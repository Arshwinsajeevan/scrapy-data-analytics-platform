# Web Data Aggregation & Analytics Platform

A Python-based data platform that extracts, stores, cleans, and analyzes structured web data from multiple public sources. Built using Scrapy, SQLite, and Pandas, this project demonstrates a complete data engineering workflow including web crawling, ETL processing, database storage, and analytics reporting.

## ğŸš€ Features
- Multi-source web scraping using Scrapy
- Structured data extraction with pagination handling
- Data storage in SQLite relational database
- ETL pipeline using Pandas and Regex
- Statistical & text-based analytics
- Automated report generation (CSV + Charts)
- Clean, scalable project architecture
- Version control using Git

## ğŸ›  Tech Stack
- Python
- Scrapy
- Pandas
- SQLite
- Matplotlib
- Regex
- Git & GitHub

## ğŸ“‚ Project Structure
```bash
web-data-aggregator/
â”‚
â”œâ”€â”€ analytics/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”œâ”€â”€ processed/
â”‚ â””â”€â”€ reports/
â”œâ”€â”€ database/
â”œâ”€â”€ scrapy_project/
â””â”€â”€ README.md


## ğŸ“Š Reports Generated
- Average book price
- Rating distribution
- Top quoted authors
- Most frequent tags
- Price distribution graphs
- Text length analysis
- Trend summaries

Reports are stored in:
data/reports/


## âš™ï¸ How to Run
pip install -r requirements.txt
scrapy crawl books_spider
scrapy crawl quotes_spider
python analytics/books_analysis.py
python analytics/quotes_analysis.py
ğŸ¯ Outcome
This project demonstrates real-world data workflow capabilities aligned with enterprise data roles including:

Data aggregation

Data cleaning

Database handling

Analytics & reporting

Independent problem solving